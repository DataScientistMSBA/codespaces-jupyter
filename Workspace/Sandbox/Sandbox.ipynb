{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en-us\"><head>\n",
       "<meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<title>Yahoo</title>\n",
       "<meta content=\"width=device-width,initial-scale=1,minimal-ui\" name=\"viewport\"/>\n",
       "<meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/>\n",
       "<style>\n",
       "  html {\n",
       "      height: 100%;\n",
       "  }\n",
       "  body {\n",
       "      background: #fafafc url(https://s.yimg.com/nn/img/sad-panda-201402200631.png) 50% 50%;\n",
       "      background-size: cover;\n",
       "      height: 100%;\n",
       "      text-align: center;\n",
       "      font: 300 18px \"helvetica neue\", helvetica, verdana, tahoma, arial, sans-serif;\n",
       "  }\n",
       "  table {\n",
       "      height: 100%;\n",
       "      width: 100%;\n",
       "      table-layout: fixed;\n",
       "      border-collapse: collapse;\n",
       "      border-spacing: 0;\n",
       "      border: none;\n",
       "  }\n",
       "  h1 {\n",
       "      font-size: 42px;\n",
       "      font-weight: 400;\n",
       "      color: #400090;\n",
       "  }\n",
       "  p {\n",
       "      color: #1A1A1A;\n",
       "  }\n",
       "  #message-1 {\n",
       "      font-weight: bold;\n",
       "      margin: 0;\n",
       "  }\n",
       "  #message-2 {\n",
       "      display: inline-block;\n",
       "      *display: inline;\n",
       "      zoom: 1;\n",
       "      max-width: 17em;\n",
       "      _width: 17em;\n",
       "  }\n",
       "      </style>\n",
       "<script>\n",
       "    document.write('<img src=\"//geo.yahoo.com/b?s=1197757129&t='+new Date().getTime()+'&src=aws&err_url='+encodeURIComponent(document.URL)+'&err=%<pssc>&test='+encodeURIComponent('%<{Bucket}cqh[:200]>')+'\" width=\"0px\" height=\"0px\"/>');var beacon = new Image();beacon.src=\"//bcn.fp.yahoo.com/p?s=1197757129&t=\"+new Date().getTime()+\"&src=aws&err_url=\"+encodeURIComponent(document.URL)+\"&err=%<pssc>&test=\"+encodeURIComponent('%<{Bucket}cqh[:200]>');\n",
       "  </script>\n",
       "</head>\n",
       "<body>\n",
       "<!-- status code : 404 -->\n",
       "<!-- Not Found on Server -->\n",
       "<table>\n",
       "<tbody><tr>\n",
       "<td>\n",
       "<img alt=\"Yahoo Logo\" src=\"https://s.yimg.com/rz/p/yahoo_frontpage_en-US_s_f_p_205x58_frontpage.png\"/>\n",
       "<h1 style=\"margin-top:20px;\">Will be right back...</h1>\n",
       "<p id=\"message-1\">Thank you for your patience.</p>\n",
       "<p id=\"message-2\">Our engineers are working quickly to resolve the issue.</p>\n",
       "</td>\n",
       "</tr>\n",
       "</tbody></table>\n",
       "</body></html>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.yahoo.com/news/comcast-business-partners-fortinet-secure-140000276.html'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "print(str(soup).count(\"Comcast\"))\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AskGPT(\"\n",
    "\n",
    "How\n",
    "\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libGL.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Create a VideoCapture object to capture video from the default camera\u001b[39;00m\n\u001b[1;32m      4\u001b[0m video_capture \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/cv2/__init__.py:181\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[39mif\u001b[39;00m DEBUG: \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mExtra Python code for\u001b[39m\u001b[39m\"\u001b[39m, submodule, \u001b[39m\"\u001b[39m\u001b[39mis loaded\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m DEBUG: \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mOpenCV loader: DONE\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 181\u001b[0m bootstrap()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/cv2/__init__.py:153\u001b[0m, in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mif\u001b[39;00m DEBUG: \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRelink everything from native cv2 module to cv2 package\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    151\u001b[0m py_module \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcv2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 153\u001b[0m native_module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39m\"\u001b[39;49m\u001b[39mcv2\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    155\u001b[0m sys\u001b[39m.\u001b[39mmodules[\u001b[39m\"\u001b[39m\u001b[39mcv2\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m py_module\n\u001b[1;32m    156\u001b[0m \u001b[39msetattr\u001b[39m(py_module, \u001b[39m\"\u001b[39m\u001b[39m_native\u001b[39m\u001b[39m\"\u001b[39m, native_module)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "\u001b[0;31mImportError\u001b[0m: libGL.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Create a VideoCapture object to capture video from the default camera\n",
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "# Check if the camera is opened successfully\n",
    "if not video_capture.isOpened():\n",
    "    print(\"Could not open video device\")\n",
    "\n",
    "# Continuously capture and display frames from the camera\n",
    "while True:\n",
    "    # Read a frame from the camera\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # Check if the frame is valid\n",
    "    if not ret:\n",
    "        print(\"Could not read frame\")\n",
    "        break\n",
    "\n",
    "    # Display the captured frame\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "    # Wait for the user to press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the VideoCapture object and close all windows\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dpkg-query: package 'libgl1-mesa-glx' is not installed and no information is available\n",
      "Use dpkg --info (= dpkg-deb --info) to examine archive files.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E: Unable to locate package libgl1-mesa-glx\n",
      "/bin/sh: 1: dnf: not found\n",
      "sudo: dnf: command not found\n",
      "dpkg-query: package 'mesa-utils' is not installed and no information is available\n",
      "Use dpkg --info (= dpkg-deb --info) to examine archive files.\n",
      "E: Unable to locate package mesa-utils\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install diffusers transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "pipe = DiffusionPipeline.from_pretrained(\"damo-vilab/text-to-video-ms-1.7b\", torch_dtype=torch.float16, variant=\"fp16\")\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "pipe.enable_model_cpu_offload()\n",
    "\n",
    "prompt = \"Spiderman is surfing\"\n",
    "video_frames = pipe(prompt, num_inference_steps=25).frames\n",
    "video_path = export_to_video(video_frames)\n",
    "video_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'/workspaces/codespaces-jupyter/Workspace/References/Files/OpenAI'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:701\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    700\u001b[0m     fpath \u001b[39m=\u001b[39m arg_lst[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 701\u001b[0m     filename \u001b[39m=\u001b[39m file_finder(fpath)\n\u001b[1;32m    702\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/utils/path.py:90\u001b[0m, in \u001b[0;36mget_py_filename\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[39mreturn\u001b[39;00m py_name\n\u001b[0;32m---> 90\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFile `\u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m` not found.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m name)\n",
      "\u001b[0;31mOSError\u001b[0m: File `'/workspaces/codespaces-jupyter/Workspace/References/Files/OpenAI'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m/workspaces/codespaces-jupyter/Workspace/References/Files/OpenAI API.ipynb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2414\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2413\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2414\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2416\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2417\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/magics/execution.py:712\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39mmatch(\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m^\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\"\u001b[39m,fpath):\n\u001b[1;32m    711\u001b[0m         warn(\u001b[39m'\u001b[39m\u001b[39mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39mun \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmypath\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmyfile.py\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 712\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    713\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    714\u001b[0m     \u001b[39mif\u001b[39;00m fpath \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmeta_path:\n",
      "\u001b[0;31mException\u001b[0m: File `'/workspaces/codespaces-jupyter/Workspace/References/Files/OpenAI'` not found."
     ]
    }
   ],
   "source": [
    "%run /workspaces/codespaces-jupyter/Workspace/References/Files/OpenAI API.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "start_sequence = \"\\nAI:\"\n",
    "restart_sequence = \"\\nHuman: \"\n",
    "\n",
    "\n",
    "def AskGPT(question, chat_log=None):\n",
    "    prompt_text = f\"{chat_log}{restart_sequence}: {question}{start_sequence}:\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=prompt_text,\n",
    "        temperature=0.9,\n",
    "        max_tokens=2000,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0.6,\n",
    "        stop=[\"\\n\"]\n",
    "    )\n",
    "    story = response[\"choices\"][0][\"text\"]\n",
    "    return str(story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' :'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AskGPT(\"\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "       \")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
